In
practice,
the
Bag-of-words
model
is
mainly
used
as
a
tool
of
feature
generation.
After
transforming
text
into
"bag
words",
we
can
calculate
various
measures
to
characterize
text.
The
most
common
type
characteristics,
or
features
calculated
from
term
frequency,
namely,
number
times
appears
in
For
example
above,
construct
following
two
lists
record
frequencies
all
distinct
words:
Each
entry
refers
count
corresponding
list
(this
also
histogram
representation).
example,
first
(which
represents
document
1),
entries
are
"1,2".
corresponds
word
"John"
which
list,
and
its
value
"1"
because
1
time.
Similarly,
second
"likes"
"2"
2
times.
This
(or
vector)
representation
does
not
preserve
order
words
original
sentences,
just
main
model.
kind
has
several
successful
applications,
for
email
filtering.
However,
necessarily
best
Common
like
"the",
"a",
"to"
almost
always
terms
with
highest
frequency
Thus,
having
high
raw
mean
that
more
important.
To
address
this
problem,
one
popular
ways
"normalize"
weight
by
inverse
tfï¿½idf.
Additionally,
specific
purpose
classification,
supervised
alternatives
have
been
developed
take
account
class
label
document.[5]
Lastly,
binary
(presence/absence
1/0)
weighting
place
some
problems.
(For
instance,
option
implemented
WEKA
machine
learning
software
system.)
